{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "fashion=tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test)=fashion.load_data()\n",
    "\n",
    "print (x_train.shape)\n",
    "print (y_train.shape)\n",
    "\n",
    "print (x_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   3   1   0   0   7   0  37   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   2   0  27  84\n",
      "   11   0   0   0   0   0   0 119   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  88 143\n",
      "  110   0   0   0   0  22  93 106   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   4   0  53 129 120\n",
      "  147 175 157 166 135 154 168 140   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  11 137 130 128\n",
      "  160 176 159 167 178 149 151 144   0   0]\n",
      " [  0   0   0   0   0   0   1   0   2   1   0   3   0   0 115 114 106 137\n",
      "  168 153 156 165 167 143 157 158  11   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   3   0   0  89 139  90  94 153\n",
      "  149 131 151 169 172 143 159 169  48   0]\n",
      " [  0   0   0   0   0   0   2   4   1   0   0   0  98 136 110 109 110 162\n",
      "  135 144 149 159 167 144 158 169 119   0]\n",
      " [  0   0   2   2   1   2   0   0   0   0  26 108 117  99 111 117 136 156\n",
      "  134 154 154 156 160 141 147 156 178   0]\n",
      " [  3   0   0   0   0   0   0  21  53  92 117 111 103 115 129 134 143 154\n",
      "  165 170 154 151 154 143 138 150 165  43]\n",
      " [  0   0  23  54  65  76  85 118 128 123 111 113 118 127 125 139 133 136\n",
      "  160 140 155 161 144 155 172 161 189  62]\n",
      " [  0  68  94  90 111 114 111 114 115 127 135 136 143 126 127 151 154 143\n",
      "  148 125 162 162 144 138 153 162 196  58]\n",
      " [ 70 169 129 104  98 100  94  97  98 102 108 106 119 120 129 149 156 167\n",
      "  190 190 196 198 198 187 197 189 184  36]\n",
      " [ 16 126 171 188 188 184 171 153 135 120 126 127 146 185 195 209 208 255\n",
      "  209 177 245 252 251 251 247 220 206  49]\n",
      " [  0   0   0  12  67 106 164 185 199 210 211 210 208 190 150  82   8   0\n",
      "    0   0 178 208 188 175 162 158 151  11]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "EPOCH=2\n",
    "cls_num=len(set(y_train))\n",
    "image_shape=(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(features,feature_columns,output_cls):\n",
    "    \n",
    "    input_layer=tf.feature_column.input_layer(features,feature_columns)\n",
    "    \n",
    "    \n",
    "#     tf.layers.conv2d   isdeprecated ,keras.layers.conv2d\n",
    "    conv1=tf.keras.layers.Conv2D(filters=16,kernel_size=[3,3],activation='relu',name='conv1')(input_layer)\n",
    "    pool1=tf.keras.layers.MaxPool2D(pool_size=(3,3))(conv1)\n",
    "    conv2=tf.keras.layers.Conv2D(filters=8,kernel_size=[5,5],activation='relu',name='conv2')(pool1)\n",
    "    flat=tf.keras.layers.Flatten()(conv2)\n",
    "    dens1=tf.keras.layers.Dense(units=128,activation='relu',name='dense1')(flat)\n",
    "    logits=tf.keras.layers.Dense(units=output_cls,name='dense_output')(dens1)\n",
    "    return logits\n",
    "def  model_fn_builder(lr):\n",
    "    # 该方法实际 创建 estimator的model_fn\n",
    "    # 可以 有其他操作\n",
    "    def model_fn(features, labels, mode, params,config): #estimator需要的model_fn 参数固定\n",
    "        '''\n",
    "        features: from input_fn的返回  切记返回的顺序\n",
    "        labels： from input_fn 的返回  切记返回的顺序\n",
    "        mode: tf.estimator.ModeKeys实例的一种\n",
    "        params: 在初始化estimator时 传入的参数列表，dict形式,或者直接使用self.params也可以\n",
    "        config:初始化estimator时 的 Runconfig\n",
    "\n",
    "        '''\n",
    "        logits=create_model(features,params['feature_columns'],params['output_cls'])\n",
    "        \n",
    "        pre_cls=tf.math.argmax(input=logits,axis=1)\n",
    "        pre_prob=tf.nn.softmax(logits=logits,axis=1)\n",
    "        \n",
    "        is_predict=mode==tf.estimator.ModeKeys.PREDICT\n",
    "        if not is_predict:\n",
    "            # train .eval\n",
    "            loss=tf.losses.sparse_softmax_cross_entropy(labels=labels,logits=logits)\n",
    "\n",
    "            def metric_fn(labels,predictions):\n",
    "                '''\n",
    "                define metrics\n",
    "                '''\n",
    "                accuracy,accuracy_update=tf.metrics.accuracy(labels=labels,predictions=predictions,name='iris_accuracy')\n",
    "    #                 auc=tf.metrics.auc(labels=labels,predictions=predictions,name='iris_auc')\n",
    "                recall,recall_update=tf.metrics.recall(labels=labels,predictions=predictions,name='iris_recall')\n",
    "                precision,precision_update=tf.metrics.precision(labels=labels,predictions=predictions,name='iris_precision')\n",
    "    #                 with tf.control_dependencies([recall,precision]):\n",
    "    #                     f1_score=f1(recall=recall,precision=precision)\n",
    "\n",
    "                return {\n",
    "                    'accuracy':(accuracy,accuracy_update),\n",
    "                    'recall':(recall,recall_update),\n",
    "                    'precision':(precision,precision_update)                  \n",
    "                }\n",
    "\n",
    "\n",
    "            if mode==tf.estimator.ModeKeys.EVAL:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,loss=loss,eval_metric_ops=metric_fn(labels,pre_cls))\n",
    "\n",
    "            # train process\n",
    "            train_op=tf.train.AdamOptimizer(learning_rate=lr).minimize(loss=loss,global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,loss=loss,train_op=train_op,eval_metric_ops=metric_fn(labels,pre_cls))\n",
    "\n",
    "\n",
    "        else:\n",
    "            predictions={'predict_cls':pre_cls,'predict_pro':pre_prob}\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,predictions=predictions)     \n",
    "    return model_fn\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(x,y,batch_size,epochs,is_train=True):\n",
    "    '''\n",
    "    创建 输入函数闭包\n",
    "    '''\n",
    "    # 可以执行其它操作\n",
    "    \n",
    "    def input_fn():\n",
    "        dataset=tf.data.Dataset.from_tensor_slices(({'images':x_train},y_train) )  \n",
    "        if is_train:\n",
    "            dataset=dataset.shuffle(1000).repeat(epochs)\n",
    "        dataset=dataset.batch(batch_size)\n",
    "        return dataset # 返回的 顺序要和 model_fn一致 或者 dataset元素 格式为（features,label）元组 也可以\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=r'F:\\testDemo\\AI\\estimator\\model\\fashion'\n",
    "params={}\n",
    "feature_columns=[tf.feature_column.numeric_column('images',shape=image_shape)]\n",
    "\n",
    "output_cls=cls_num\n",
    "params['feature_columns']=feature_columns\n",
    "params['output_cls']=output_cls\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_NER",
   "language": "python",
   "name": "ner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
